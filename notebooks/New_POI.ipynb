{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4fa03dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport boto3\\nimport json\\nimport pandas as pd\\nimport geopy\\nfrom geopy.geocoders import Nominatim\\nimport time\\n\\n# the below extension properly formats a cell after it is run\\n%load_ext nb_black\\n\\n# Set the maximum number of rows to 200\\npd.set_option(\\\"display.max_rows\\\", 200)\\nimport pandas as pd\\n\\n# Set the maximum number of columns to 200\\npd.set_option(\\\"display.max_columns\\\", 200)\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport boto3\\nimport json\\nimport pandas as pd\\nimport geopy\\nfrom geopy.geocoders import Nominatim\\nimport time\\n\\n# the below extension properly formats a cell after it is run\\n%load_ext nb_black\\n\\n# Set the maximum number of rows to 200\\npd.set_option(\\\"display.max_rows\\\", 200)\\nimport pandas as pd\\n\\n# Set the maximum number of columns to 200\\npd.set_option(\\\"display.max_columns\\\", 200)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "\n",
    "# the below extension properly formats a cell after it is run\n",
    "%load_ext nb_black\n",
    "\n",
    "# Set the maximum number of rows to 200\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "import pandas as pd\n",
    "\n",
    "# Set the maximum number of columns to 200\n",
    "pd.set_option(\"display.max_columns\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fab5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creating an S3 client object\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Specifying the name of the bucket\n",
    "bucket_name = 'capstonehaystacks'\n",
    "\n",
    "# Downloading the all_zips_grocery_store.json file from S3 and parsing it into data1\n",
    "response1 = s3.get_object(Bucket=bucket_name, Key='all_zips_grocery_store.json')\n",
    "json_content1 = response1['Body'].read().decode('utf-8')\n",
    "grocery_json = json.loads(json_content1)\n",
    "\n",
    "# Downloading the all_zips_restaurant.json file from S3 and parsing it into data2\n",
    "response2 = s3.get_object(Bucket=bucket_name, Key='all_zips_restaurant.json')\n",
    "json_content2 = response2['Body'].read().decode('utf-8')\n",
    "restaurant_json = json.loads(json_content2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49b608a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to flatten json files and convert to dataframes\n",
    "\n",
    "def json_to_df(json):\n",
    "    \"\"\"\n",
    "    Convert a list of JSON objects containing location information into a Pandas DataFrame.\n",
    "\n",
    "    :param json: A list of JSON objects containing location information.\n",
    "    :return: A Pandas DataFrame containing the location information.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "\n",
    "    for j in json:\n",
    "        for result in j['responce']['results']:\n",
    "            try:\n",
    "                # extracting the state from the compound code and check if it's 'GA'\n",
    "                state_ = result['plus_code']['compound_code'].split(',')[-2].strip()\n",
    "                poi_types_ = result['types']\n",
    "\n",
    "                if state_ == 'GA':\n",
    "                    # extracting relevant information from the JSON object\n",
    "                    place_id_ = result['place_id']\n",
    "                    latitude_ = result['geometry']['location']['lat']\n",
    "                    longitude_ = result['geometry']['location']['lng']\n",
    "                    rating_ = result['rating']\n",
    "                    num_ratings_ = result['user_ratings_total']\n",
    "                    name_ = result['name']\n",
    "\n",
    "                    # appending the extracted information to the data list\n",
    "                    data.append([latitude_, longitude_, state_, place_id_, name_, rating_, num_ratings_, poi_types_])\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    # creating df using the data list\n",
    "    df = pd.DataFrame(data, columns=['latitude', 'longitude', 'state', 'place_id', 'name', 'rating', 'num_ratings', 'poi_types'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880d152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grocery_df = json_to_df(grocery_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea3be7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3190, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grocery_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc0c174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_df = json_to_df(restaurant_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95ff63c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5283, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ff27c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_df = pd.concat([grocery_df, restaurant_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0f17e053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"poi_df[\\\"primary_type\\\"] = poi_df[\\\"poi_types\\\"].apply(lambda x: x[0])\";\n",
       "                var nbb_formatted_code = \"poi_df[\\\"primary_type\\\"] = poi_df[\\\"poi_types\\\"].apply(lambda x: x[0])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_df[\"primary_type\"] = poi_df[\"poi_types\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8978ca05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude        0\n",
       "longitude       0\n",
       "state           0\n",
       "place_id        0\n",
       "name            0\n",
       "rating          0\n",
       "num_ratings     0\n",
       "poi_types       0\n",
       "primary_type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"poi_df.isna().sum()\";\n",
       "                var nbb_formatted_code = \"poi_df.isna().sum()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d511d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restaurant                 3058\n",
       "meal_takeaway              1006\n",
       "point_of_interest           645\n",
       "bar                         499\n",
       "lodging                     335\n",
       "cafe                        269\n",
       "church                      263\n",
       "meal_delivery               224\n",
       "convenience_store           186\n",
       "gas_station                 179\n",
       "store                       128\n",
       "general_contractor           98\n",
       "secondary_school             77\n",
       "car_repair                   71\n",
       "doctor                       62\n",
       "drugstore                    55\n",
       "post_office                  50\n",
       "grocery_or_supermarket       49\n",
       "local_government_office      48\n",
       "health                       43\n",
       "home_goods_store             42\n",
       "bakery                       42\n",
       "bank                         41\n",
       "department_store             40\n",
       "tourist_attraction           40\n",
       "finance                      39\n",
       "school                       37\n",
       "park                         34\n",
       "clothing_store               33\n",
       "hospital                     29\n",
       "real_estate_agency           27\n",
       "insurance_agency             27\n",
       "car_dealer                   25\n",
       "pharmacy                     25\n",
       "bowling_alley                24\n",
       "university                   24\n",
       "library                      23\n",
       "primary_school               22\n",
       "night_club                   22\n",
       "electronics_store            20\n",
       "furniture_store              20\n",
       "police                       20\n",
       "courthouse                   19\n",
       "shopping_mall                19\n",
       "funeral_home                 19\n",
       "dentist                      18\n",
       "food                         18\n",
       "museum                       18\n",
       "campground                   17\n",
       "movie_theater                17\n",
       "gym                          17\n",
       "accounting                   16\n",
       "shoe_store                   16\n",
       "hardware_store               16\n",
       "beauty_salon                 16\n",
       "supermarket                  15\n",
       "travel_agency                15\n",
       "storage                      14\n",
       "plumber                      13\n",
       "liquor_store                 12\n",
       "city_hall                    11\n",
       "veterinary_care              11\n",
       "airport                      11\n",
       "roofing_contractor           10\n",
       "atm                          10\n",
       "lawyer                       10\n",
       "hair_care                     9\n",
       "rv_park                       8\n",
       "art_gallery                   8\n",
       "moving_company                8\n",
       "fire_station                  7\n",
       "movie_rental                  6\n",
       "book_store                    6\n",
       "train_station                 5\n",
       "cemetery                      5\n",
       "jewelry_store                 5\n",
       "car_rental                    5\n",
       "laundry                       5\n",
       "spa                           5\n",
       "stadium                       5\n",
       "electrician                   4\n",
       "painter                       4\n",
       "amusement_park                3\n",
       "florist                       3\n",
       "place_of_worship              3\n",
       "zoo                           2\n",
       "pet_store                     2\n",
       "parking                       1\n",
       "car_wash                      1\n",
       "physiotherapist               1\n",
       "transit_station               1\n",
       "premise                       1\n",
       "bicycle_store                 1\n",
       "Name: primary_type, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 52;\n",
       "                var nbb_unformatted_code = \"poi_df['primary_type'].value_counts()\";\n",
       "                var nbb_formatted_code = \"poi_df[\\\"primary_type\\\"].value_counts()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_df['primary_type'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2facd4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"from geopy.exc import GeocoderTimedOut, GeocoderServiceError\\n\\ndef get_tract_zip(lat, lon):\\n    max_retries = 3\\n    retry_delay = 5  # seconds\\n    for i in range(max_retries):\\n        try:\\n            location = geolocator.reverse(f\\\"{lat}, {lon}\\\", timeout=5)\\n            address = location.raw['address']\\n            tract = address.get('census_tract', None)\\n            zipcode = address.get('postcode', None)\\n            return (tract, zipcode)\\n        except (GeocoderTimedOut, GeocoderServiceError):\\n            print(f\\\"Request timed out or service error on attempt {i+1} of {max_retries}\\\")\\n            if i < max_retries - 1:\\n                time.sleep(retry_delay)\\n    return (None, None)\";\n",
       "                var nbb_formatted_code = \"from geopy.exc import GeocoderTimedOut, GeocoderServiceError\\n\\n\\ndef get_tract_zip(lat, lon):\\n    max_retries = 3\\n    retry_delay = 5  # seconds\\n    for i in range(max_retries):\\n        try:\\n            location = geolocator.reverse(f\\\"{lat}, {lon}\\\", timeout=5)\\n            address = location.raw[\\\"address\\\"]\\n            tract = address.get(\\\"census_tract\\\", None)\\n            zipcode = address.get(\\\"postcode\\\", None)\\n            return (tract, zipcode)\\n        except (GeocoderTimedOut, GeocoderServiceError):\\n            print(\\n                f\\\"Request timed out or service error on attempt {i+1} of {max_retries}\\\"\\n            )\\n            if i < max_retries - 1:\\n                time.sleep(retry_delay)\\n    return (None, None)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Took two hours to run and didnt work\n",
    "geolocator = Nominatim(user_agent=\"user_agent\")\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "\n",
    "def get_tract_zip(lat, lon):\n",
    "    max_retries = 3\n",
    "    retry_delay = 5  # seconds\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            location = geolocator.reverse(f\"{lat}, {lon}\", timeout=5)\n",
    "            address = location.raw['address']\n",
    "            tract = address.get('census_tract', None)\n",
    "            zipcode = address.get('postcode', None)\n",
    "            return (tract, zipcode)\n",
    "        except (GeocoderTimedOut, GeocoderServiceError):\n",
    "            print(f\"Request timed out or service error on attempt {i+1} of {max_retries}\")\n",
    "            if i < max_retries - 1:\n",
    "                time.sleep(retry_delay)\n",
    "    return (None, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "feea1de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 2 of 3\n",
      "Request timed out or service error on attempt 3 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 2 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n",
      "Request timed out or service error on attempt 1 of 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2g/w2gh47jx2d536k1lqy8yjms40000gn/T/ipykernel_6779/3178302372.py:1: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  grocery_df[['census_tract', 'zip_code']] = poi_df.apply(lambda x: pd.Series(get_tract_zip(x['latitude'], x['longitude'])), axis=1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grocery_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcensus_tract\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip_code\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m poi_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: pd\u001b[38;5;241m.\u001b[39mSeries(get_tract_zip(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m], x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m])), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3643\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_frame(key, value)\n\u001b[1;32m   3642\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (Series, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, Index)):\n\u001b[0;32m-> 3643\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   3645\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_frame_value(key, value)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3687\u001b[0m, in \u001b[0;36mDataFrame._setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3685\u001b[0m     check_key_length(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, key, value)\n\u001b[1;32m   3686\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k1, k2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(key, value\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[0;32m-> 3687\u001b[0m         \u001b[38;5;28mself\u001b[39m[k1] \u001b[38;5;241m=\u001b[39m value[k2]\n\u001b[1;32m   3689\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(value):\n\u001b[1;32m   3690\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m key:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4532\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4530\u001b[0m \u001b[38;5;66;03m# We should never get here with DataFrame value\u001b[39;00m\n\u001b[1;32m   4531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[0;32m-> 4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m   4535\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:10999\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  10995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m  10996\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  10997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m  10998\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[0;32m> 10999\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m  11001\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m  11002\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible index of inserted column with frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m  11003\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m  11004\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:10994\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[0;34m(value, index)\u001b[0m\n\u001b[1;32m  10992\u001b[0m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[1;32m  10993\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m> 10994\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m  10995\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m  10996\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[1;32m  10997\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[1;32m  10998\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4672\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4668\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   4669\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m passed as both positional and keyword argument\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4670\u001b[0m         )\n\u001b[1;32m   4671\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index})\n\u001b[0;32m-> 4672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4966\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4963\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   4965\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 4966\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   4968\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4986\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   4981\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[1;32m   4982\u001b[0m     labels, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[1;32m   4983\u001b[0m )\n\u001b[1;32m   4985\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m-> 4986\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_with_indexers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4987\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4989\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4991\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4992\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   4993\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5032\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   5029\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m   5031\u001b[0m \u001b[38;5;66;03m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[0;32m-> 5032\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mnew_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5035\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5037\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_dups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5039\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5040\u001b[0m \u001b[38;5;66;03m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   5041\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:679\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dups:\n\u001b[0;32m--> 679\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_can_reindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequested axis not found in manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:4107\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[0;34m(self, indexer)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;66;03m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[1;32m   4106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_as_unique \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[0;32m-> 4107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"grocery_df[['census_tract', 'zip_code']] = poi_df.apply(lambda x: pd.Series(get_tract_zip(x['latitude'], x['longitude'])), axis=1)\";\n",
       "                var nbb_formatted_code = \"grocery_df[[\\\"census_tract\\\", \\\"zip_code\\\"]] = poi_df.apply(\\n    lambda x: pd.Series(get_tract_zip(x[\\\"latitude\\\"], x[\\\"longitude\\\"])), axis=1\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grocery_df[['census_tract', 'zip_code']] = poi_df.apply(lambda x: pd.Series(get_tract_zip(x['latitude'], x['longitude'])), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20e8763a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>state</th>\n",
       "      <th>place_id</th>\n",
       "      <th>name</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_ratings</th>\n",
       "      <th>poi_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.791987</td>\n",
       "      <td>-84.385677</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJoz4--E8E9YgRxpSO8xC1jj0</td>\n",
       "      <td>Residence Inn Atlanta Midtown/Peachtree at 17th</td>\n",
       "      <td>4.1</td>\n",
       "      <td>723</td>\n",
       "      <td>[lodging, point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33.790216</td>\n",
       "      <td>-84.388776</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJh-lI8FoE9YgRyKGKYvLpvA8</td>\n",
       "      <td>Artmore Hotel</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1106</td>\n",
       "      <td>[lodging, point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.799427</td>\n",
       "      <td>-84.392589</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJFybLXVQE9YgRTePNqN08VnU</td>\n",
       "      <td>Atlanta Peachtree Station</td>\n",
       "      <td>3.6</td>\n",
       "      <td>163</td>\n",
       "      <td>[train_station, transit_station, point_of_inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.797403</td>\n",
       "      <td>-84.387181</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJw7eoDVIE9YgRx5tdBoAEvZc</td>\n",
       "      <td>WSB-TV Channel 2 Action News</td>\n",
       "      <td>4.5</td>\n",
       "      <td>224</td>\n",
       "      <td>[point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.807117</td>\n",
       "      <td>-84.384343</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJS6x_52YE9YgRvjzX8rkA3xI</td>\n",
       "      <td>Influence Health - Atlanta, GA</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6</td>\n",
       "      <td>[point_of_interest, establishment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5278</th>\n",
       "      <td>30.800110</td>\n",
       "      <td>-84.920406</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJ4ba6nYUq7YgRSUgZ-9bRWG4</td>\n",
       "      <td>Papa Doc's Lakeside Grill</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14</td>\n",
       "      <td>[restaurant, point_of_interest, food, establis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5279</th>\n",
       "      <td>30.800136</td>\n",
       "      <td>-84.920361</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJIWan0f9H7YgRJRTfaocDBWQ</td>\n",
       "      <td>Pop's Dockside Grill</td>\n",
       "      <td>4.6</td>\n",
       "      <td>180</td>\n",
       "      <td>[restaurant, point_of_interest, food, establis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5280</th>\n",
       "      <td>33.451486</td>\n",
       "      <td>-81.925004</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJCc0PltvL-YgRwMyapR2fSIQ</td>\n",
       "      <td>Subway</td>\n",
       "      <td>4.0</td>\n",
       "      <td>325</td>\n",
       "      <td>[meal_takeaway, restaurant, food, point_of_int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5281</th>\n",
       "      <td>34.978807</td>\n",
       "      <td>-85.348016</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJ9XcT4ptcYIgRK4bk_0yBwVc</td>\n",
       "      <td>The Lookout Mountain Club</td>\n",
       "      <td>4.6</td>\n",
       "      <td>115</td>\n",
       "      <td>[restaurant, food, point_of_interest, health, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5282</th>\n",
       "      <td>34.973637</td>\n",
       "      <td>-85.347900</td>\n",
       "      <td>GA</td>\n",
       "      <td>ChIJc0168phcYIgRiYeutclvLNk</td>\n",
       "      <td>Rock City’s Cafe 7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>89</td>\n",
       "      <td>[restaurant, food, point_of_interest, establis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8473 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       latitude  longitude state                     place_id  \\\n",
       "0     33.791987 -84.385677    GA  ChIJoz4--E8E9YgRxpSO8xC1jj0   \n",
       "1     33.790216 -84.388776    GA  ChIJh-lI8FoE9YgRyKGKYvLpvA8   \n",
       "2     33.799427 -84.392589    GA  ChIJFybLXVQE9YgRTePNqN08VnU   \n",
       "3     33.797403 -84.387181    GA  ChIJw7eoDVIE9YgRx5tdBoAEvZc   \n",
       "4     33.807117 -84.384343    GA  ChIJS6x_52YE9YgRvjzX8rkA3xI   \n",
       "...         ...        ...   ...                          ...   \n",
       "5278  30.800110 -84.920406    GA  ChIJ4ba6nYUq7YgRSUgZ-9bRWG4   \n",
       "5279  30.800136 -84.920361    GA  ChIJIWan0f9H7YgRJRTfaocDBWQ   \n",
       "5280  33.451486 -81.925004    GA  ChIJCc0PltvL-YgRwMyapR2fSIQ   \n",
       "5281  34.978807 -85.348016    GA  ChIJ9XcT4ptcYIgRK4bk_0yBwVc   \n",
       "5282  34.973637 -85.347900    GA  ChIJc0168phcYIgRiYeutclvLNk   \n",
       "\n",
       "                                                 name  rating  num_ratings  \\\n",
       "0     Residence Inn Atlanta Midtown/Peachtree at 17th     4.1          723   \n",
       "1                                       Artmore Hotel     3.9         1106   \n",
       "2                           Atlanta Peachtree Station     3.6          163   \n",
       "3                        WSB-TV Channel 2 Action News     4.5          224   \n",
       "4                      Influence Health - Atlanta, GA     4.5            6   \n",
       "...                                               ...     ...          ...   \n",
       "5278                        Papa Doc's Lakeside Grill     4.1           14   \n",
       "5279                             Pop's Dockside Grill     4.6          180   \n",
       "5280                                           Subway     4.0          325   \n",
       "5281                        The Lookout Mountain Club     4.6          115   \n",
       "5282                               Rock City’s Cafe 7     4.2           89   \n",
       "\n",
       "                                              poi_types  \n",
       "0           [lodging, point_of_interest, establishment]  \n",
       "1           [lodging, point_of_interest, establishment]  \n",
       "2     [train_station, transit_station, point_of_inte...  \n",
       "3                    [point_of_interest, establishment]  \n",
       "4                    [point_of_interest, establishment]  \n",
       "...                                                 ...  \n",
       "5278  [restaurant, point_of_interest, food, establis...  \n",
       "5279  [restaurant, point_of_interest, food, establis...  \n",
       "5280  [meal_takeaway, restaurant, food, point_of_int...  \n",
       "5281  [restaurant, food, point_of_interest, health, ...  \n",
       "5282  [restaurant, food, point_of_interest, establis...  \n",
       "\n",
       "[8473 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"poi_df\";\n",
       "                var nbb_formatted_code = \"poi_df\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ad5e8aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File uploaded to S3 with ETag: \"80763b318b33c5a430f30e4e6965a7d9\"\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"# Create an S3 resource instead of using the S3 client that was used earlier\\ns3R = boto3.resource('s3')\\n\\n# Convert the poi_df DataFrame to a csv buffer in memory\\ncsv_buffer = io.StringIO()\\npoi_df.to_csv(csv_buffer, index=False)\\n\\n# Naming the file for AWS storage\\nfile_name = 'poi_combined_haystack.csv'\\n\\n# Uploading the file to S3 and printing the response\\nresponse = s3R.Object(bucket_name, file_name).put(Body=csv_buffer.getvalue())\\nprint(f\\\"File uploaded to S3 with ETag: {response['ETag']}\\\") # Checking the status to confirm it was uploaded\";\n",
       "                var nbb_formatted_code = \"# Create an S3 resource instead of using the S3 client that was used earlier\\ns3R = boto3.resource(\\\"s3\\\")\\n\\n# Convert the poi_df DataFrame to a csv buffer in memory\\ncsv_buffer = io.StringIO()\\npoi_df.to_csv(csv_buffer, index=False)\\n\\n# Naming the file for AWS storage\\nfile_name = \\\"poi_combined_haystack.csv\\\"\\n\\n# Uploading the file to S3 and printing the response\\nresponse = s3R.Object(bucket_name, file_name).put(Body=csv_buffer.getvalue())\\nprint(\\n    f\\\"File uploaded to S3 with ETag: {response['ETag']}\\\"\\n)  # Checking the status to confirm it was uploaded\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an S3 resource instead of using the S3 client that was used earlier\n",
    "s3R = boto3.resource('s3')\n",
    "\n",
    "# Convert the poi_df DataFrame to a csv buffer in memory\n",
    "csv_buffer = io.StringIO()\n",
    "poi_df.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# Naming the file for AWS storage\n",
    "file_name = 'poi_combined_haystack.csv'\n",
    "\n",
    "# Uploading the file to S3 and printing the response\n",
    "response = s3R.Object(bucket_name, file_name).put(Body=csv_buffer.getvalue())\n",
    "print(f\"File uploaded to S3 with ETag: {response['ETag']}\") # Checking the status to confirm it was uploaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a10128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
